{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import ResNet18_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant Classes: ['Potato', 'Tomato']\n",
      "Disease Classes: ['Potato___Early_blight', 'Tomato___Bacterial_spot', 'Tomato___Late_blight', 'Potato___Late_blight', 'Tomato___Early_blight', 'Potato___healthy']\n"
     ]
    }
   ],
   "source": [
    "# Dynamic Class Fetching\n",
    "def get_classes_from_dataset(dataset_path):\n",
    "    plant_classes = []\n",
    "    disease_classes = []\n",
    "    \n",
    "    for plant_folder in os.listdir(dataset_path):\n",
    "        if os.path.isdir(os.path.join(dataset_path, plant_folder)):\n",
    "            plant_classes.append(plant_folder)  # Add plant type (e.g., Potato, Tomato)\n",
    "            for disease_folder in os.listdir(os.path.join(dataset_path, plant_folder)):\n",
    "                if os.path.isdir(os.path.join(dataset_path, plant_folder, disease_folder)):\n",
    "                    disease_classes.append(disease_folder)  # Add disease (e.g., Early_blight, Healthy)\n",
    "    \n",
    "    # Removing duplicates, since disease names might repeat across plants\n",
    "    disease_classes = list(set(disease_classes))\n",
    "    \n",
    "    return plant_classes, disease_classes\n",
    "\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = 'dataset'\n",
    "\n",
    "# Get plant and disease classes dynamically from dataset\n",
    "plant_classes, disease_classes = get_classes_from_dataset(dataset_path)\n",
    "\n",
    "# Print out the classes for reference\n",
    "print(f'Plant Classes: {plant_classes}')\n",
    "print(f'Disease Classes: {disease_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class for loading images\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, dataset_path, plant_classes, disease_classes, transform=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.plant_classes = plant_classes\n",
    "        self.disease_classes = disease_classes\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load image paths and labels\n",
    "        for plant_idx, plant in enumerate(plant_classes):\n",
    "            for disease_idx, disease in enumerate(disease_classes):\n",
    "                folder_path = os.path.join(dataset_path, plant, disease)\n",
    "                if os.path.exists(folder_path):\n",
    "                    for filename in os.listdir(folder_path):\n",
    "                        if filename.endswith(\".JPG\"):\n",
    "                            self.image_paths.append(os.path.join(folder_path, filename))\n",
    "                            self.labels.append((plant_idx, disease_idx))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for input images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "dataset = PlantDiseaseDataset(dataset_path, plant_classes, disease_classes, transform)\n",
    "\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.2, stratify=dataset.labels)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MultiOutputModel\n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, num_plants, num_diseases):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        self.base_model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, 512)\n",
    "        self.plant_fc = nn.Linear(512, num_plants)\n",
    "        self.disease_fc = nn.Linear(512, num_diseases)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.base_model(x)\n",
    "        plant_output = self.plant_fc(features)\n",
    "        disease_output = self.disease_fc(features)\n",
    "        return plant_output, disease_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = MultiOutputModel(len(plant_classes), len(disease_classes))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\preet\\AppData\\Local\\Temp\\ipykernel_30996\\22668387.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  plant_labels = torch.tensor(plant_labels)\n",
      "C:\\Users\\preet\\AppData\\Local\\Temp\\ipykernel_30996\\22668387.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  disease_labels = torch.tensor(disease_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7574359308396067\n",
      "Epoch [2/10], Loss: 0.3867612212896347\n",
      "Epoch [3/10], Loss: 0.41671855699803145\n",
      "Epoch [4/10], Loss: 0.3766050634639604\n",
      "Epoch [5/10], Loss: 0.41221226890172274\n",
      "Epoch [6/10], Loss: 0.33398997145039694\n",
      "Epoch [7/10], Loss: 0.3807034127946411\n",
      "Epoch [8/10], Loss: 0.246326643275097\n",
      "Epoch [9/10], Loss: 0.09768552472482302\n",
      "Epoch [10/10], Loss: 0.3495805774283196\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        # Assuming labels is already a tuple (plant_labels, disease_labels)\n",
    "        plant_labels, disease_labels = labels\n",
    "        plant_labels = torch.tensor(plant_labels)\n",
    "        disease_labels = torch.tensor(disease_labels)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        plant_outputs, disease_outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        plant_loss = criterion(plant_outputs, plant_labels)\n",
    "        disease_loss = criterion(disease_outputs, disease_labels)\n",
    "        loss = plant_loss + disease_loss\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "model.eval()\n",
    "correct_plant = 0                       //USE THIS NEXT TIME \n",
    "correct_disease = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_batches = len(val_loader)  # Total number of batches\n",
    "    for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
    "        # Print every 100th batch for progress monitoring\n",
    "        if batch_idx % 100 == 0:\n",
    "            remaining_batches = total_batches - batch_idx\n",
    "            print(f\"Processing batch {batch_idx + 1}/{total_batches} - {remaining_batches} batches remaining\")\n",
    "\n",
    "        # Assuming labels is a tuple (plant_labels, disease_labels)\n",
    "        plant_labels, disease_labels = labels\n",
    "        plant_labels = plant_labels.to(torch.long)  # Ensure the correct tensor type\n",
    "        disease_labels = disease_labels.to(torch.long)  # Ensure the correct tensor type\n",
    "\n",
    "        # Forward pass\n",
    "        plant_outputs, disease_outputs = model(inputs)\n",
    "\n",
    "        # Get predictions\n",
    "        _, plant_pred = torch.max(plant_outputs, 1)\n",
    "        _, disease_pred = torch.max(disease_outputs, 1)\n",
    "\n",
    "        # Update the counters\n",
    "        correct_plant += (plant_pred == plant_labels).sum().item()\n",
    "        correct_disease += (disease_pred == disease_labels).sum().item()\n",
    "        total += inputs.size(0)  # Use batch size for total count\n",
    "\n",
    "# Print accuracy\n",
    "print(f'Accuracy on validation set: Plant: {100 * correct_plant / total:.2f}%, Disease: {100 * correct_disease / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: Plant: 97.11%, Disease: 91.68%\n"
     ]
    }
   ],
   "source": [
    "# Validate the model\n",
    "model.eval()\n",
    "correct_plant = 0\n",
    "correct_disease = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        # Assuming labels is a tuple (plant_labels, disease_labels)\n",
    "        plant_labels, disease_labels = labels\n",
    "        plant_labels = plant_labels.to(torch.long)  # Ensure the correct tensor type\n",
    "        disease_labels = disease_labels.to(torch.long)  # Ensure the correct tensor type\n",
    "\n",
    "        # Forward pass\n",
    "        plant_outputs, disease_outputs = model(inputs)\n",
    "\n",
    "        # Get predictions\n",
    "        _, plant_pred = torch.max(plant_outputs, 1)\n",
    "        _, disease_pred = torch.max(disease_outputs, 1)\n",
    "\n",
    "        # Update the counters\n",
    "        correct_plant += (plant_pred == plant_labels).sum().item()\n",
    "        correct_disease += (disease_pred == disease_labels).sum().item()\n",
    "        total += inputs.size(0)  # Use batch size for total count\n",
    "\n",
    "# Print accuracy\n",
    "print(f'Accuracy on validation set: Plant: {100 * correct_plant / total:.2f}%, Disease: {100 * correct_disease / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'plant_disease_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
